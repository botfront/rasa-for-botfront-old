import os
import logging
import time
from rasa_addons.superagent import SuperAgent
from rasa_core.policies import PolicyEnsemble
from rasa_core.actions.action import RemoteAction
from rasa_core.domain import Domain
from rasa_core.utils import EndpointConfig
from botfront import BotfrontInterpreter, BotfrontDispatcher
from threading import Thread
from botfront.nlg.generator import LegacyBotfrontNLG
import utils as bf_utils

logger = logging.getLogger(__name__)


def _utter_responses(self, responses,  # type: List[Dict[Text, Any]]
                     dispatcher,  # type: Dispatcher
                     tracker  # type: DialogueStateTracker
                     ):
    # type: (...) -> None
    """Use the responses generated by the action endpoint and utter them.

    Uses the normal dispatcher to utter the responses from the action
    endpoint."""

    for response in responses:
        if "template" in response:
            kwargs = response.copy()
            del kwargs["template"]
            draft = dispatcher.nlg.generate(
                    response["template"],
                    tracker,
                    dispatcher.output_channel,
                    **kwargs)
            dispatcher.utter_response(draft)
        else:
            dispatcher.utter_response(response)


class BotfrontAgent(SuperAgent):

    @classmethod
    def load(cls,
             path=None,
             project_id=None,
             nlu_models=None,
             base_url=None,
             chatbase_api_key=None,
             tracker_store_version=None,
             domain=None,
             policies=None,
             interpreter=None,
             generator=None,
             tracker_store=None,
             action_endpoint=None,
             nlu_endpoint=None,
             rules=None,
             rules_endpoint=None,
             create_dispatcher=None,
             model_server=None,
             wait_time_between_pulls=None,
             create_nlg=None):

        # Override function to allow sequences
        RemoteAction._utter_responses = _utter_responses

        agent = SuperAgent.load(
            path=path,
            domain=domain if domain else Domain.load(os.path.join(path, "domain.yml")) if not model_server else None,
            policies=policies if policies else PolicyEnsemble.load(path) if not model_server else None,
            interpreter=interpreter if interpreter else None,
            generator=None,
            tracker_store=tracker_store,
            action_endpoint=action_endpoint,
            rules=rules,
            model_server=model_server,
            wait_time_between_pulls=wait_time_between_pulls,
            create_dispatcher=lambda sender_id, output_channel, nlg: BotfrontDispatcher(sender_id, output_channel, nlg),
            create_nlg=lambda generator, domain: LegacyBotfrontNLG(base_url, project_id)
        )

        if interpreter is None and isinstance(nlu_models, EndpointConfig):
            if nlu_models.kwargs.get('models') is None:
                start_nlu_models_info_pulling_in_worker(nlu_models, wait_time_between_pulls,
                                                        agent, project_id, nlu_endpoint)
                logger.debug("Started a worker to pull nlu models info every {} seconds"
                               .format(wait_time_between_pulls))
            elif isinstance(nlu_models.kwargs.get('models'), dict):
                agent.interpreter = BotfrontInterpreter(nlu_models.kwargs.get('models'), nlu_endpoint, project_id)
                logger.debug("NLU interpreter created".format(wait_time_between_pulls))
            else:
                raise ValueError("nlu_models_info should either contain a url property to fetch model info from a "
                                 "remote server or contain a 'models' property which must me a dictionary mapping "
                                 "language codes (en,fr) to model ids")

        return agent


def start_nlu_models_info_pulling_in_worker(endpoint, wait_time_between_pulls, agent, project_id, nlu_endpoint):
    # type: (EndpointConfig, int, Agent, Text, EndpointConfig) -> None

    worker = Thread(target=_run_nlu_models_info_pulling_worker,
                    args=(endpoint, wait_time_between_pulls, agent, project_id, nlu_endpoint))
    worker.setDaemon(True)
    worker.start()


def _run_nlu_models_info_pulling_worker(endpoint, wait_time_between_pulls, agent, project_id, nlu_endpoint):
    # type: (EndpointConfig, int, Agent, Text, EndpointConfig) -> None
    while True:
        try:
            models = bf_utils.load_from_remote(endpoint, "models_server", temp_file=False)
            default_language = models.get("default_language", None);
            if default_language:
                del models["default_language"]
            agent.interpreter = BotfrontInterpreter(
                models=models,
                endpoint=nlu_endpoint,
                project_name=project_id,
                default_language=default_language)
        except Exception as e:
            logger.warning("Failed pulling nlu models info from server: {}".format(e))
        finally:
            time.sleep(wait_time_between_pulls)